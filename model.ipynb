{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf3e8851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import wrangle as w\n",
    "import explore as e\n",
    "import env\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, RFE, f_regression, SequentialFeatureSelector\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer, PolynomialFeatures\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4a6daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = w.wrangle_zillow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f01d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = w.split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cd8f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, validate_scaled, test_scaled = w.scale_data(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08527434",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = train_scaled[['bedrooms', 'bathrooms', 'sq_feet']]\n",
    "y_train = train[['tax_value']]\n",
    "\n",
    "x_validate_scaled = validate_scaled[['bedrooms', 'bathrooms', 'sq_feet']]\n",
    "y_validate = validate[['tax_value']]\n",
    "\n",
    "x_test_scaled = test_scaled[['bedrooms', 'bathrooms', 'sq_feet']]\n",
    "y_test = test[['tax_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3af34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline():\n",
    "#def get_baseline():\n",
    "    y_train['tax_value_pred_mean']= y_train['tax_value'].mean()\n",
    "    y_validate['tax_value_pred_mean']= y_validate['tax_value'].mean()\n",
    "\n",
    "    y_train['tax_value_pred_median'] = y_train['tax_value'].median()\n",
    "    y_validate['tax_value_pred_median'] = y_validate['tax_value'].median()\n",
    "\n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_mean)**(1/2)\n",
    "    rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_mean)**(1/2)\n",
    "\n",
    "    print(\"RMSE using Mean\\nTrain/In-Sample: \", round(rmse_train, 2), \n",
    "          \"\\nValidate/Out-of-Sample: \", round(rmse_validate, 2))\n",
    "    \n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_median)**(1/2)\n",
    "    rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_median)**(1/2)\n",
    "\n",
    "    print(\"\\nRMSE using Median\\nTrain/In-Sample: \", round(rmse_train, 2), \n",
    "          \"\\nValidate/Out-of-Sample: \", round(rmse_validate, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e164679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ols():\n",
    "    # create the model object\n",
    "    lm = LinearRegression(normalize=True)\n",
    "\n",
    "    # fit the model to our training data. We must specify the column in y_train, \n",
    "    # since we have converted it to a dataframe from a series! \n",
    "    lm.fit(x_train_scaled, y_train.tax_value)\n",
    "\n",
    "    # predict train\n",
    "    y_train['tax_value_pred_lm'] = lm.predict(x_train_scaled)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_lm)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_validate['tax_value_pred_lm'] = lm.predict(x_validate_scaled)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_lm)**(1/2)\n",
    "\n",
    "    print(\"RMSE for OLS using LinearRegression\\nTraining/In-Sample: \", rmse_train, \n",
    "          \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d9e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lassolars():\n",
    "    lars = LassoLars(alpha=1.0)\n",
    "    #scaler = MinMaxScaler()\n",
    "    #x_train_scaled = x_train_scaled.copy()\n",
    "    #x_train_scaled[['bedrooms','bathrooms','sq_feet','year_built','tax_amount','fips']] = scaler.fit_transform(x_train_scaled)\n",
    "    #x_validate_scaled = x_validate_scaled.copy()\n",
    "    #x_validate_scaled[['bedrooms','bathrooms','sq_feet','year_built','tax_amount','fips']] = scaler.fit_transform(x_validate_scaled)\n",
    "\n",
    "    lars.fit(x_train_scaled, y_train.tax_value)\n",
    "\n",
    "    y_train['tax_value_pred_lars'] = lars.predict(x_train_scaled)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_lars)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_validate['tax_value_pred_lars'] = lars.predict(x_validate_scaled)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_lars)**(1/2)\n",
    "\n",
    "    print(\"RMSE for Lasso + Lars\\nTraining/In-Sample: \", rmse_train, \n",
    "          \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6d3feb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweedie():\n",
    "    \n",
    "    # create the model object\n",
    "    glm = TweedieRegressor(power=1, alpha=0)\n",
    "\n",
    "    # fit the model to our training data. We must specify the column in y_train, \n",
    "    # since we have converted it to a dataframe from a series! \n",
    "    glm.fit(x_train_scaled, y_train.tax_value)\n",
    "\n",
    "    # predict train\n",
    "    y_train['tax_value_pred_glm'] = glm.predict(x_train_scaled)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_glm)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_validate['tax_value_pred_glm'] = glm.predict(x_validate_scaled)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_glm)**(1/2)\n",
    "\n",
    "    print(\"RMSE for GLM using Tweedie, power=1 & alpha=0\\nTraining/In-Sample: \", rmse_train, \n",
    "          \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e7af440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poly():\n",
    "    # make the polynomial features to get a new set of features\n",
    "    pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "    # fit and transform X_train_scaled\n",
    "    x_train_scaled_degree2 = pf.fit_transform(x_train_scaled)\n",
    "\n",
    "    # transform X_validate_scaled & X_test_scaled\n",
    "    x_validate_scaled_degree2 = pf.transform(x_validate_scaled)\n",
    "    x_test_scaled_degree2 = pf.transform(x_test_scaled)\n",
    "    \n",
    "    # create the model object\n",
    "    lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "    # fit the model to our training data. We must specify the column in y_train, \n",
    "    # since we have converted it to a dataframe from a series! \n",
    "    lm2.fit(x_train_scaled_degree2, y_train.tax_value)\n",
    "\n",
    "    # predict train\n",
    "    y_train['tax_value_pred_lm2'] = lm2.predict(x_train_scaled_degree2)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_lm2)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_validate['tax_value_pred_lm2'] = lm2.predict(x_validate_scaled_degree2)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_lm2)**(1/2)\n",
    "\n",
    "    print(\"RMSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \", rmse_train, \n",
    "          \"\\nValidation/Out-of-Sample: \", rmse_validate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "610b62c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_poly_test(x_train_scaled, y_test):\n",
    "def get_poly_test():\n",
    "    # make the polynomial features to get a new set of features\n",
    "    pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "    # fit and transform X_train_scaled\n",
    "    x_train_scaled_degree2 = pf.fit_transform(x_train_scaled)\n",
    "\n",
    "    # transform X_validate_scaled & X_test_scaled\n",
    "    x_validate_scaled_degree2 = pf.transform(x_validate_scaled)\n",
    "    x_test_scaled_degree2 = pf.transform(x_test_scaled)\n",
    "    \n",
    "    # create the model object\n",
    "    lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "    # fit the model to our training data. We must specify the column in y_train, \n",
    "    # since we have converted it to a dataframe from a series! \n",
    "    lm2.fit(x_train_scaled_degree2, y_train.tax_value)\n",
    "\n",
    "    # predict train\n",
    "    y_train['tax_value_pred_lm2'] = lm2.predict(x_train_scaled_degree2)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_lm2)**(1/2)\n",
    "\n",
    "    # predict test\n",
    "    y_test['tax_value_pred_lm2'] = lm2.predict(x_test_scaled_degree2)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_test = mean_squared_error(y_test.tax_value, y_test.tax_value_pred_lm2)**(1/2)\n",
    "\n",
    "    print(\"RMSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \", rmse_train, \n",
    "          \"\\nTest/Out-of-Sample: \", rmse_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d751612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_performance(y, yhat, featureN = 2):\n",
    "        # A version of R Squared which may be more accurate than when done by hand\n",
    "        r2 = r2_score(y, yhat)\n",
    "        # Adjusted R Squared\n",
    "        #adjR2= 1-(1-r2)*(len(y)-1)/(len(y)-featureN-1)\n",
    "        print('R^2 Coefficient for Variance: ', r2)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5580d4b",
   "metadata": {},
   "source": [
    "# R^2 related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3dcc6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_1():\n",
    "#def get_baseline():\n",
    "    y_train['tax_value_pred_mean']= y_train['tax_value'].mean()\n",
    "    y_validate['tax_value_pred_mean']= y_validate['tax_value'].mean()\n",
    "\n",
    "    y_train['tax_value_pred_median'] = y_train['tax_value'].median()\n",
    "    y_validate['tax_value_pred_median'] = y_validate['tax_value'].median()\n",
    "\n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_mean)**(1/2)\n",
    "    rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_mean)**(1/2)\n",
    "\n",
    "    \n",
    "    \n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_median)**(1/2)\n",
    "    rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_median)**(1/2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d67b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ols_1():\n",
    "    # create the model object\n",
    "    lm = LinearRegression(normalize=True)\n",
    "\n",
    "    # fit the model to our training data. We must specify the column in y_train, \n",
    "    # since we have converted it to a dataframe from a series! \n",
    "    lm.fit(x_train_scaled, y_train.tax_value)\n",
    "\n",
    "    # predict train\n",
    "    y_train['tax_value_pred_lm'] = lm.predict(x_train_scaled)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_lm)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_validate['tax_value_pred_lm'] = lm.predict(x_validate_scaled)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_lm)**(1/2)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7e1f777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lassolars_1():\n",
    "    lars = LassoLars(alpha=1.0)\n",
    "    #scaler = MinMaxScaler()\n",
    "    #x_train_scaled = x_train_scaled.copy()\n",
    "    #x_train_scaled[['bedrooms','bathrooms','sq_feet','year_built','tax_amount','fips']] = scaler.fit_transform(x_train_scaled)\n",
    "    #x_validate_scaled = x_validate_scaled.copy()\n",
    "    #x_validate_scaled[['bedrooms','bathrooms','sq_feet','year_built','tax_amount','fips']] = scaler.fit_transform(x_validate_scaled)\n",
    "\n",
    "    lars.fit(x_train_scaled, y_train.tax_value)\n",
    "\n",
    "    y_train['tax_value_pred_lars'] = lars.predict(x_train_scaled)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_lars)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_validate['tax_value_pred_lars'] = lars.predict(x_validate_scaled)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_lars)**(1/2)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c8ec5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweedie_1():\n",
    "    \n",
    "    # create the model object\n",
    "    glm = TweedieRegressor(power=1, alpha=0)\n",
    "\n",
    "    # fit the model to our training data. We must specify the column in y_train, \n",
    "    # since we have converted it to a dataframe from a series! \n",
    "    glm.fit(x_train_scaled, y_train.tax_value)\n",
    "\n",
    "    # predict train\n",
    "    y_train['tax_value_pred_glm'] = glm.predict(x_train_scaled)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_glm)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_validate['tax_value_pred_glm'] = glm.predict(x_validate_scaled)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_glm)**(1/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c2012e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poly_1():\n",
    "    # make the polynomial features to get a new set of features\n",
    "    pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "    # fit and transform X_train_scaled\n",
    "    x_train_scaled_degree2 = pf.fit_transform(x_train_scaled)\n",
    "\n",
    "    # transform X_validate_scaled & X_test_scaled\n",
    "    x_validate_scaled_degree2 = pf.transform(x_validate_scaled)\n",
    "    x_test_scaled_degree2 = pf.transform(x_test_scaled)\n",
    "    \n",
    "    # create the model object\n",
    "    lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "    # fit the model to our training data. We must specify the column in y_train, \n",
    "    # since we have converted it to a dataframe from a series! \n",
    "    lm2.fit(x_train_scaled_degree2, y_train.tax_value)\n",
    "\n",
    "    # predict train\n",
    "    y_train['tax_value_pred_lm2'] = lm2.predict(x_train_scaled_degree2)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_lm2)**(1/2)\n",
    "\n",
    "    # predict validate\n",
    "    y_validate['tax_value_pred_lm2'] = lm2.predict(x_validate_scaled_degree2)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_validate = mean_squared_error(y_validate.tax_value, y_validate.tax_value_pred_lm2)**(1/2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1aac2d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_poly_test(x_train_scaled, y_test):\n",
    "def get_poly_test_1():\n",
    "    # make the polynomial features to get a new set of features\n",
    "    pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "    # fit and transform X_train_scaled\n",
    "    x_train_scaled_degree2 = pf.fit_transform(x_train_scaled)\n",
    "\n",
    "    # transform X_validate_scaled & X_test_scaled\n",
    "    x_validate_scaled_degree2 = pf.transform(x_validate_scaled)\n",
    "    x_test_scaled_degree2 = pf.transform(x_test_scaled)\n",
    "    \n",
    "    # create the model object\n",
    "    lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "    # fit the model to our training data. We must specify the column in y_train, \n",
    "    # since we have converted it to a dataframe from a series! \n",
    "    lm2.fit(x_train_scaled_degree2, y_train.tax_value)\n",
    "\n",
    "    # predict train\n",
    "    y_train['tax_value_pred_lm2'] = lm2.predict(x_train_scaled_degree2)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_train = mean_squared_error(y_train.tax_value, y_train.tax_value_pred_lm2)**(1/2)\n",
    "\n",
    "    # predict test\n",
    "    y_test['tax_value_pred_lm2'] = lm2.predict(x_test_scaled_degree2)\n",
    "\n",
    "    # evaluate: rmse\n",
    "    rmse_test = mean_squared_error(y_test.tax_value, y_test.tax_value_pred_lm2)**(1/2)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc0b4c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance():\n",
    "    #use all models to get a fully updated y_train and a y_test dataframe\n",
    "    get_baseline_1()\n",
    "    get_ols_1()\n",
    "    get_lassolars_1()\n",
    "    get_tweedie_1()\n",
    "    get_poly_1()\n",
    "    get_poly_test_1()\n",
    "    \n",
    "    calc_performance(y_test.tax_value, y_test.tax_value_pred_lm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af234177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c3db03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
